{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_vua_model_cvf.ipynb","provenance":[{"file_id":"1--pV1kpb861uZz2AzodugRkKdUFxkVUP","timestamp":1647139075263}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OorRP8DmGiVJ","executionInfo":{"status":"ok","timestamp":1647138923832,"user_tz":360,"elapsed":3590,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"38cd44da-53c2-43ad-f7d8-3c69c6c42626"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","ROOT = '/content/drive'\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","source":["import os\n","import sys\n","from os.path import join \n","repo_dir = '/content/drive/MyDrive/gong-metaphor-detection'"],"metadata":{"id":"jdbJjOe9G9T1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install requirements (takes a while)\n","#!cd drive/MyDrive/Repos/gong-metaphor-detection/; pip install -r requirements.txt"],"metadata":{"id":"uxx58pzZHJ8b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install 'transformers==3.5.1'"],"metadata":{"id":"tdLjjXFJKdV0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647138937297,"user_tz":360,"elapsed":7198,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"b913e8a8-7224-4134-a706-82551660d391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.63.0)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 36.8 MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 23.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.21.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 45.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (3.0.7)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"]}]},{"cell_type":"code","source":["!pip install torch==1.4.0"],"metadata":{"id":"KDgam-CNYsOa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647139045345,"user_tz":360,"elapsed":100631,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"c3556216-596d-4aae-85ac-111c02ffc368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.6 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n"]}]},{"cell_type":"code","source":["!pip install scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvWsFdCwjoOy","executionInfo":{"status":"ok","timestamp":1647117421552,"user_tz":360,"elapsed":3874,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"8056bb87-0d34-46ec-f97a-8f6efbb912c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n"]}]},{"cell_type":"code","source":["!cd drive/MyDrive/Repos/gong-metaphor-detection/; bash shell-scripts/run_vua_seq_model.sh\n"],"metadata":{"id":"Gy6a7oIVH0UM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647117543945,"user_tz":360,"elapsed":68701,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"b399e4a6-0841-42cd-8092-6bd6bedd188b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["03/12/2022 20:38:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","Downloading: 100% 482/482 [00:00<00:00, 840kB/s]\n","Downloading: 100% 899k/899k [00:00<00:00, 5.23MB/s]\n","Downloading: 100% 456k/456k [00:00<00:00, 3.13MB/s]\n","Downloading: 100% 1.43G/1.43G [00:32<00:00, 44.1MB/s]\n","03/12/2022 20:38:47 - INFO - modeling_roberta_metaphor -   hidden_size: 1024, pos_dim: 8, feature_dim: 128\n","03/12/2022 20:38:47 - INFO - modeling_roberta_metaphor -   classifier dim: 1032\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForMetaphorDetection: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForMetaphorDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMetaphorDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForMetaphorDetection were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pos_emb.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","03/12/2022 20:38:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='data/VUA', dataset='VUA', device=device(type='cuda'), do_lower_case=True, do_predict=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=True, feature_dim=128, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, labels='', learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='roberta-large', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='output/VUA/modeltest/', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=18, per_gpu_train_batch_size=6, pos_dim=8, pos_vocab_size=43, save_steps=500, seed=42, server_ip='', server_port='', tokenizer_name='', use_features=False, use_pos=True, warmup_steps=500, weight_decay=0.0)\n","03/12/2022 20:38:54 - INFO - __main__ -   Loading features from cached file data/VUA/cached_train_roberta-large_256\n","class 0: 103571.0, class 1: 13051.0\n","weights: [0.22520203531876684, 1.7871733966745844]\n","train size: 5058, dev_size: 1265\n","03/12/2022 20:39:00 - INFO - __main__ -   ***** Running training *****\n","03/12/2022 20:39:00 - INFO - __main__ -     Num examples = 5058\n","03/12/2022 20:39:00 - INFO - __main__ -     Num Epochs = 5\n","03/12/2022 20:39:00 - INFO - __main__ -     Instantaneous batch size per GPU = 6\n","03/12/2022 20:39:00 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 6\n","03/12/2022 20:39:00 - INFO - __main__ -     Gradient Accumulation steps = 1\n","03/12/2022 20:39:00 - INFO - __main__ -     Total optimization steps = 4215\n","03/12/2022 20:39:00 - INFO - __main__ -    Weighted cross-entropy class weights: [0.22520203531876684, 1.7871733966745844]\n","Epoch:   0% 0/5 [00:00<?, ?it/s]\n","Iteration:   0% 0/843 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\n","Iteration:   0% 1/843 [00:00<09:01,  1.56it/s]\u001b[A\n","Iteration:   0% 2/843 [00:01<08:39,  1.62it/s]\u001b[A\n","Iteration:   0% 3/843 [00:01<08:28,  1.65it/s]\u001b[A\n","Iteration:   0% 4/843 [00:02<08:22,  1.67it/s]\u001b[A\n","Iteration:   1% 5/843 [00:03<08:18,  1.68it/s]\u001b[A\n","Iteration:   1% 6/843 [00:04<09:29,  1.47it/s]\n","Epoch:   0% 0/5 [00:04<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"run_metaphor_detection.py\", line 757, in <module>\n","    main()\n","  File \"run_metaphor_detection.py\", line 729, in main\n","    class_weights, tokenizer, pad_token_label_id)\n","  File \"run_metaphor_detection.py\", line 193, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 195, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}]}]}